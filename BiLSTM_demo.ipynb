{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fc50f902-4f09-4bc9-9755-17ab23f0cd5d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-24T14:38:38.578396Z",
          "iopub.status.busy": "2024-04-24T14:38:38.577861Z",
          "iopub.status.idle": "2024-04-24T14:38:38.585978Z",
          "shell.execute_reply": "2024-04-24T14:38:38.584278Z",
          "shell.execute_reply.started": "2024-04-24T14:38:38.578354Z"
        },
        "id": "fc50f902-4f09-4bc9-9755-17ab23f0cd5d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "684f41c5-dd5b-44df-addf-c0603f1bb5ac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-24T14:38:38.589061Z",
          "iopub.status.busy": "2024-04-24T14:38:38.588634Z",
          "iopub.status.idle": "2024-04-24T14:39:12.264957Z",
          "shell.execute_reply": "2024-04-24T14:39:12.263565Z",
          "shell.execute_reply.started": "2024-04-24T14:38:38.589025Z"
        },
        "id": "684f41c5-dd5b-44df-addf-c0603f1bb5ac"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pickle\n",
        "\n",
        "# Load the Bi_LSTM\n",
        "model = load_model('Bi_LSTM_ED.h5')\n",
        "\n",
        "# Load the tokenizer\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "# Load max lengths\n",
        "with open('lengths.json', 'r') as f:\n",
        "    lengths = json.load(f)\n",
        "\n",
        "max_length_claims = lengths['max_length_claims']\n",
        "max_length_evidence = lengths['max_length_evidence']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6e44c643-641a-4696-b32d-c3ed7fc95d6b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-24T14:39:12.267348Z",
          "iopub.status.busy": "2024-04-24T14:39:12.266858Z",
          "iopub.status.idle": "2024-04-24T14:39:16.494820Z",
          "shell.execute_reply": "2024-04-24T14:39:16.492718Z",
          "shell.execute_reply.started": "2024-04-24T14:39:12.267309Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e44c643-641a-4696-b32d-c3ed7fc95d6b",
        "outputId": "a77e2f26-b614-4b6d-c25a-f5b620b355a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147/147 [==============================] - 6s 17ms/step\n",
            "(4691, 1)\n"
          ]
        }
      ],
      "source": [
        "# Load trial data\n",
        "trial_data = pd.read_csv('test.csv')\n",
        "trial_data['Claim'] = trial_data['Claim'].astype(str)\n",
        "trial_data['Evidence'] = trial_data['Evidence'].astype(str)\n",
        "\n",
        "# Tokenization\n",
        "trial_claims_seq = tokenizer.texts_to_sequences(trial_data['Claim'].tolist())\n",
        "trial_evidence_seq = tokenizer.texts_to_sequences(trial_data['Evidence'].tolist())\n",
        "\n",
        "# Pad the sequences to the max length\n",
        "trial_claims_pad = pad_sequences(trial_claims_seq, maxlen=28)\n",
        "trial_evidence_pad = pad_sequences(trial_evidence_seq, maxlen=273)\n",
        "\n",
        "# Predict the labels\n",
        "predictions = model.predict([trial_claims_pad, trial_evidence_pad])\n",
        "predictions_trial = (predictions > 0.5).astype(int)\n",
        "\n",
        "# Display the shape of the predictions\n",
        "print(predictions_trial.shape)\n",
        "\n",
        "# Save the predictions to an Excel file\n",
        "prediction_df = pd.DataFrame(predictions_trial, columns=['prediction'])\n",
        "prediction_df.to_csv('output.csv', mode='w', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}